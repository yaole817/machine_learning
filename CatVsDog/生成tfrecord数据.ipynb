{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"./data/train/\"\n",
    "test_path = \"./data/test/\"\n",
    "LABEL_CAT = 0\n",
    "LABEL_DOG = 1\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 cats\n",
      "There are 12500 dogs\n",
      "\n",
      "Transform start......\n",
      ">>Coverting image 25000 / 25000 \n",
      "Transform done!\n"
     ]
    }
   ],
   "source": [
    "def get_files(file_dir):\n",
    "    '''\n",
    "    Args:\n",
    "        file_dir: file directory\n",
    "    Returns:\n",
    "        list of images and labels\n",
    "    '''\n",
    "    cats, label_cats = [], []\n",
    "    dogs, label_dogs = [], []\n",
    "    for file in os.listdir(file_dir):\n",
    "        name = file.split('.')\n",
    "        if name[0]=='cat':\n",
    "            cats.append(file_dir + file)\n",
    "            label_cats.append(LABEL_CAT)\n",
    "        else:\n",
    "            dogs.append(file_dir + file)\n",
    "            label_dogs.append(LABEL_DOG)\n",
    "    print('There are %d cats\\nThere are %d dogs' %(len(cats), len(dogs)))\n",
    "    \n",
    "    image_list = np.hstack((cats, dogs))\n",
    "    label_list = np.hstack((label_cats, label_dogs))\n",
    "    \n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    "    \n",
    "    return image_list, label_list\n",
    " \n",
    "def int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    " \n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "## 将数据保存为tfrecord 的格式\n",
    "def convert_to_tfrecord(images, labels, save_dir, name):\n",
    "    '''convert all images and labels to one tfrecord file.\n",
    "    Args:\n",
    "        images: list of image directories, string type\n",
    "        labels: list of labels, int type\n",
    "        save_dir: the directory to save tfrecord file, e.g.: '/home/folder1/'\n",
    "        name: the name of tfrecord file, string type, e.g.: 'train'\n",
    "    Return:\n",
    "        no return\n",
    "    Note:\n",
    "        converting needs some time, be patient...\n",
    "    '''\n",
    "    \n",
    "    filename =  save_dir + name + '.tfrecords'\n",
    "    n_samples = len(labels)\n",
    "    \n",
    "    if np.shape(images)[0] != n_samples:\n",
    "        raise ValueError('Images size %d does not match label size %d.' %(images.shape[0], n_samples))\n",
    "    \n",
    "    # wait some time here, transforming need some time based on the size of your data.\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    print('\\nTransform start......')\n",
    "    for i in np.arange(0, n_samples):\n",
    "        try:\n",
    "            sys.stdout.write(\"\\r>>Coverting image %d / %d \" % (i+1, n_samples))\n",
    "            sys.stdout.flush()\n",
    "#             img = Image.open(images[i])\n",
    "#             img_raw = img.tobytes() \n",
    "#             label = int(labels[i])\n",
    "            image = cv2.imread(images[i])\n",
    "            image = cv2.resize(image, (208, 208))\n",
    "            b, g, r = cv2.split(image)\n",
    "            rgb_image = cv2.merge([r,g,b])\n",
    "            image_raw = rgb_image.tostring()\n",
    "            label = int(labels[i])\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                                        'label':int64_feature(label),\n",
    "                                        'image_raw': bytes_feature(image_raw)}))\n",
    "            writer.write(example.SerializeToString())\n",
    "        except IOError as e:\n",
    "            print('Could not read:', images[i])\n",
    "            print('error: %s' %e)\n",
    "            print('Skip it!\\n')\n",
    "    sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    print('Transform done!')\n",
    "\n",
    "train_images, train_labels = get_files(train_path)\n",
    "convert_to_tfrecord(train_images, train_labels, \"tfrecoard/\", \"CatVsDog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
